{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2bdb5f5-1459-4260-9ff5-9779628e0a79",
   "metadata": {},
   "source": [
    "Title\n",
    "\n",
    "Introduction:\n",
    "Provide some relevant background information on the topic so that someone unfamiliar with it will be prepared to understand the rest of your proposal\n",
    "Clearly state the question you will try to answer with your project\n",
    "Identify and describe the dataset that will be used to answer the question\n",
    "\n",
    "\n",
    "Preliminary exploratory data analysis:\n",
    "Demonstrate that the dataset can be read from the web into R \n",
    "Clean and wrangle your data into a tidy format\n",
    "Using only training data, summarize the data in at least one table (this is exploratory data analysis). An example of a useful table could be one that reports the number of observations in each class, the means of the predictor variables you plan to use in your analysis and how many rows have missing data. \n",
    "Using only training data, visualize the data with at least one plot relevant to the analysis you plan to do (this is exploratory data analysis). An example of a useful visualization could be one that compares the distributions of each of the predictor variables you plan to use in your analysis.\n",
    "\n",
    "\n",
    "\n",
    "Methods:\n",
    "Explain how you will conduct either your data analysis and which variables/columns you will use. Note - you do not need to use all variables/columns that exist in the raw data set. In fact, that's often not a good idea. For each variable think: is this a useful variable for prediction?\n",
    "Describe at least one way that you will visualize the results\n",
    "\n",
    "\n",
    "Expected outcomes and significance:\n",
    "What do you expect to find?\n",
    "What impact could such findings have?\n",
    "What future questions could this lead to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1fabead-2788-42da-84ec-0215c68c7e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(rvest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44df54ac-417a-40e3-a5c9-59a433d2f7a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: 'group_project/heart.csv' does not exist in current working directory ('/home/jovyan').\n",
     "output_type": "error",
     "traceback": [
      "Error: 'group_project/heart.csv' does not exist in current working directory ('/home/jovyan').\nTraceback:\n",
      "1. read_csv(\"group_project/heart.csv\")",
      "2. vroom::vroom(file, delim = \",\", col_names = col_names, col_types = col_types, \n .     col_select = {\n .         {\n .             col_select\n .         }\n .     }, id = id, .name_repair = name_repair, skip = skip, n_max = n_max, \n .     na = na, quote = quote, comment = comment, skip_empty_rows = skip_empty_rows, \n .     trim_ws = trim_ws, escape_double = TRUE, escape_backslash = FALSE, \n .     locale = locale, guess_max = guess_max, show_col_types = show_col_types, \n .     progress = progress, altrep = lazy, num_threads = num_threads)",
      "3. vroom_(file, delim = delim %||% col_types$delim, col_names = col_names, \n .     col_types = col_types, id = id, skip = skip, col_select = col_select, \n .     name_repair = .name_repair, na = na, quote = quote, trim_ws = trim_ws, \n .     escape_double = escape_double, escape_backslash = escape_backslash, \n .     comment = comment, skip_empty_rows = skip_empty_rows, locale = locale, \n .     guess_max = guess_max, n_max = n_max, altrep = vroom_altrep(altrep), \n .     num_threads = num_threads, progress = progress)",
      "4. (function (path, write = FALSE) \n . {\n .     if (is.raw(path)) {\n .         return(rawConnection(path, \"rb\"))\n .     }\n .     if (!is.character(path)) {\n .         return(path)\n .     }\n .     if (is_url(path)) {\n .         if (requireNamespace(\"curl\", quietly = TRUE)) {\n .             con <- curl::curl(path)\n .         }\n .         else {\n .             rlang::inform(\"`curl` package not installed, falling back to using `url()`\")\n .             con <- url(path)\n .         }\n .         ext <- tolower(tools::file_ext(path))\n .         return(switch(ext, zip = , bz2 = , xz = {\n .             close(con)\n .             stop(\"Reading from remote `\", ext, \"` compressed files is not supported,\\n\", \n .                 \"  download the files locally first.\", call. = FALSE)\n .         }, gz = gzcon(con), con))\n .     }\n .     p <- split_path_ext(basename(path))\n .     if (write) {\n .         path <- normalizePath(path, mustWork = FALSE)\n .     }\n .     else {\n .         path <- check_path(path)\n .     }\n .     if (rlang::is_installed(\"archive\")) {\n .         formats <- archive_formats(p$extension)\n .         extension <- p$extension\n .         while (is.null(formats) && nzchar(extension)) {\n .             extension <- split_path_ext(extension)$extension\n .             formats <- archive_formats(extension)\n .         }\n .         if (!is.null(formats)) {\n .             p$extension <- extension\n .             if (write) {\n .                 if (is.null(formats[[1]])) {\n .                   return(archive::file_write(path, filter = formats[[2]]))\n .                 }\n .                 return(archive::archive_write(path, p$path, format = formats[[1]], \n .                   filter = formats[[2]]))\n .             }\n .             if (is.null(formats[[1]])) {\n .                 return(archive::file_read(path, filter = formats[[2]]))\n .             }\n .             return(archive::archive_read(path, format = formats[[1]], \n .                 filter = formats[[2]]))\n .         }\n .     }\n .     if (!write) {\n .         compression <- detect_compression(path)\n .     }\n .     else {\n .         compression <- NA\n .     }\n .     if (is.na(compression)) {\n .         compression <- tools::file_ext(path)\n .     }\n .     if (write && compression == \"zip\") {\n .         stop(\"Can only read from, not write to, .zip\", call. = FALSE)\n .     }\n .     switch(compression, gz = gzfile(path, \"\"), bz2 = bzfile(path, \n .         \"\"), xz = xzfile(path, \"\"), zip = zipfile(path, \"\"), \n .         if (!has_trailing_newline(path)) {\n .             file(path)\n .         } else {\n .             path\n .         })\n . })(\"group_project/heart.csv\")",
      "5. check_path(path)",
      "6. stop(\"'\", path, \"' does not exist\", if (!is_absolute_path(path)) {\n .     paste0(\" in current working directory ('\", getwd(), \"')\")\n . }, \".\", call. = FALSE)"
     ]
    }
   ],
   "source": [
    "heart_data <- read_csv(\"group_project/heart.csv\")\n",
    "heart_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4c3efa-bfc0-4311-97af-c3d057ef1882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02815e12-4cc0-4892-9814-4922c2691215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
